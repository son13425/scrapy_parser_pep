# Асинхронный парсер PEP

## Краткое описание проекта.

В проекте реализован парсинг данных со страниц стандартов PEP Python на базе фреймворка Scrapy.
Парсер выводит собранную информацию в два файла .csv:
1. В первый файл выводится список всех PEP: номер, название и статус.
2. Второй файл содержит сводку по статусам PEP — сколько найдено документов в каждом статусе (статус, количество). В последней строке этого файла выводится общее количество всех документов.
Парсер сохраняет данные в файлы .csv в директорию results/ в корне проекта.


### Технологии.
```
Python 3, Scrapy
```
### Как запустить проект.

- Cоздать и активировать виртуальное окружение:

```
python3 -m venv venv
```

```
source venv/Scripts/activate
```

- Установить зависимости из файла requirements.txt:

```
python3 -m pip install --upgrade pip
```

```
pip install -r requirements.txt
```

- Запуск парсера:
```
scrapy crawl pep
```

### Автор.
[Оксана Широкова](https://github.com/son13425)

## Лицензия
Проект выпущены под лицензией [MIT](https://github.com/son13425/scrapy_parser_pep/blob/master/COPYING.txt)
